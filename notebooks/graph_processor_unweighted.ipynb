{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Notebook for unweighted graph analysis"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "For all the pythonic graph modifications, we use networkx as it is easy! On the other hand, graph-tool is completely written in C++ and is orders of magnitude faster than networkx. So we use it for computations on graphs."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Method\n",
      "\n",
      "1. Get the central nodes using eigenvector centralities.\n",
      "2. Remove the rubbish nodes that you are most confident of.\n",
      "2. Get communities from thus minimally cleaned graph.\n",
      "3. Further clean each community using the central nodes."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import graph_tool.all as gt\n",
      "import networkx as nx\n",
      "import community as c\n",
      "\n",
      "%matplotlib tk\n",
      "rcParams['figure.figsize'] = 16, 12"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "gt_g = gt.load_graph(file_name='/homedtic/gkoduri/workspace/relation-extraction/data/carnatic_link_graph_0.1.graphml', \n",
      "                    fmt='xml')\n",
      "print gt_g.num_vertices(), gt_g.num_edges()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "nx_g = nx.read_graphml('/homedtic/gkoduri/workspace/relation-extraction/data/carnatic_link_graph_0.1.graphml',\n",
      "                       node_type=unicode)\n",
      "print nx_g.number_of_nodes(), nx_g.number_of_edges()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##1. Get the central nodes\n",
      "\n",
      "1. Plot how the number of relations per node varies as we keep increasing the eig_centrality threshold to remove spurious nodes. \n",
      "2. Get the eig_value corresponding to the peak in that plot.\n",
      "3. Get the nodes setting that eig_value as threshold. These are the nodes which we are most confident are relevant!\n",
      "4. Get another lower bound of that eig_value such that we can discard the nodes which we are most confident are rubbish!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#eig_data = gt.eigenvector(gt_g, weight=gt_g.edge_properties[\"weight\"])\n",
      "eig_data = gt.eigenvector(gt_g)\n",
      "#eig_data = gt.katz(gt_g)\n",
      "#eig_data[0] is the largest eigenvalue of weighted adjacency matrix\n",
      "#eig_data[1] has the vertex property map with eigenvector centralities for each vertex\n",
      "print eig_data[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#covert the eig values to be used easily with networkx\n",
      "gt_labelmap = gt_g.vertex_properties['_graphml_vertex_id']\n",
      "eig_centralities = {}\n",
      "for v in gt_g.vertices():\n",
      "    eig_centralities[gt_labelmap[v].decode('utf-8')] = eig_data[1][v]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Just have a look at some values!\n",
      "nodes = [\"m. s. subbulakshmi\", \"t. m. krishna\", \"carnatic wars\", \"abhogi\", \"telugu literature\", \n",
      "         \"s. p. balasubrahmanyam\", \"kingdom of mysore\", \"philip v. francis\"]\n",
      "\n",
      "print [(n, eig_centralities[n]) for n in nodes]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* **Plot how the number of relations per node varies as we keep increasing the eig_centrality threshold to remove spurious nodes.** "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tempg = nx_g.copy()\n",
      "eig_limits = np.arange(0.00001, 0.1, 0.0003)\n",
      "edges = []\n",
      "nodes = []\n",
      "y = []\n",
      "for eig_limit in eig_limits:\n",
      "    nbunch = [n for n,v in eig_centralities.items() if v < eig_limit]\n",
      "    tempg.remove_nodes_from(nbunch)\n",
      "    \n",
      "    edges.append(tempg.number_of_edges())\n",
      "    nodes.append(tempg.number_of_nodes())\n",
      "    if nodes[-1] == 0: break\n",
      "    y.append(1.0*edges[-1]/nodes[-1])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plot(eig_limits[:len(y)], y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* **Get the eig_value corresponding to the peak in that plot.**\n",
      "* **Get the nodes setting that eig_value as threshold. These are the nodes which we are most confident are relevant!**"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "thresh = 0.025\n",
      "nodes = [i for i in nx_g.nodes_iter() if eig_centralities[i] > thresh]\n",
      "central_nodes = nodes\n",
      "print len(central_nodes)\n",
      "sorted(central_nodes)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* **Get another lower bound of that eig_value such that we can discard the nodes which we are most confident are rubbish!**\n",
      "\n",
      "    **TODO**: Automatically setting the bound"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "thresh = 0.001\n",
      "nodes = [i for i in nx_g.nodes_iter() if eig_centralities[i] > thresh]\n",
      "cg = nx_g.subgraph(nodes)\n",
      "print nx_g.number_of_nodes(), nx_g.number_of_edges()\n",
      "print cg.number_of_nodes(), cg.number_of_edges()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**What are the properties of the graph with only these central nodes, and how do they compare to the original graph?**\n",
      "\n",
      "* Diameter (nx.diameter)\n",
      "* Size (number of edges)\n",
      "* Clustering coefficient (nx.average_clustering)\n",
      "* Maximal independent set (nx.maximal_independent_set) --> *needs to be run multiple times and an average taken*\n",
      "* Clique number (nx.clique.graph_clique_number)\n",
      "* Algebraic connectivity (Second smallest eigen value of laplacian matrix of g)\n",
      "* Cheeger constant (TODO)\n",
      "* Minimum node/edge cut (nx.minimum_edge_cut or nx.minimum_node_cut)\n",
      "* Matchings (nx.matching.maximal_matching)\n",
      "* Estrada index (nx.estrada_index)\n",
      "* Vertex cover (networkx_approximate.py)\n",
      "\n",
      "\n",
      "**Other measures that can be considered when adding less good nodes to central nodes:**\n",
      "\n",
      "* Closeness vitality (related to weiner index, nx.closeness_vitality) --> *Is too slow!*"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import cStringIO"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def propmap_len(vertices, propmap):\n",
      "    count = 0\n",
      "    for v in vertices:\n",
      "        if propmap[v]:\n",
      "            count += 1\n",
      "    return count"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Convert graphs from networkx to graph-tool format**"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def convert_graph(src_g, to=\"graphtool\"):\n",
      "    buf = cStringIO.StringIO()\n",
      "    if to == \"graphtool\":\n",
      "        nx.write_graphml(src_g, buf, encoding='utf-8')\n",
      "        buf.flush()\n",
      "        buf.reset()\n",
      "        dest_g = gt.Graph()\n",
      "        dest_g.load(buf, fmt=\"xml\")\n",
      "    else:\n",
      "        src_g.save(buf, fmt=\"xml\")\n",
      "        buf.flush()\n",
      "        buf.reset()\n",
      "        dest_g = nx.read_graphml(buf, node_type=unicode)\n",
      "    return dest_g"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cg = nx_g.subgraph(nodes)\n",
      "cg = convert_graph(cg)\n",
      "\n",
      "central_g = nx_g.subgraph(central_nodes)\n",
      "central_g = convert_graph(central_g)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Diameter**"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "res_central = gt.pseudo_diameter(central_g)\n",
      "res_ext = gt.pseudo_diameter(cg)\n",
      "res_all = gt.pseudo_diameter(gt_g)\n",
      "print res_central[0], res_ext[0], res_all[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Maximal independent vertex set**"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "res = gt.max_independent_vertex_set(central_g)\n",
      "print propmap_len(central_g.vertices(), res)\n",
      "\n",
      "res = gt.max_independent_vertex_set(cg)\n",
      "print propmap_len(cg.vertices(), res)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Maximal matching**"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "res = gt.max_cardinality_matching(central_g)\n",
      "#print propmap_len(central_g.edges(), res)\n",
      "print sum(res[0].a)\n",
      "\n",
      "res = gt.max_cardinality_matching(cg)\n",
      "print sum(res[0].a)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Algebraic connectivity**"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lap = gt.laplacian(central_g)\n",
      "eig_vals = np.linalg.eigvals(lap.todense())\n",
      "eig_vals = sort(eig_vals)\n",
      "print eig_vals[1],\n",
      "\n",
      "lap = gt.laplacian(cg)\n",
      "eig_vals = np.linalg.eigvals(lap.todense())\n",
      "eig_vals = sort(eig_vals)\n",
      "print eig_vals[1]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Min cut**"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print gt.min_cut(central_g, central_g.edge_properties[\"weight\"])[0] #, len(nx.minimum_edge_cut(cg))\n",
      "print gt.min_cut(cg, cg.edge_properties[\"weight\"])[0] #, len(nx.minimum_node_cut(cg))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Plot how all these measures vary as the number of nodes are increased**"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "eig_limits = np.arange(0.025, 0.0001, -0.0003)\n",
      "edges = []\n",
      "nodes = []\n",
      "diameters = []\n",
      "maxind_vertsets = []\n",
      "max_matches = []\n",
      "alg_conn = []\n",
      "min_cut = []\n",
      "\n",
      "for eig_limit in eig_limits:\n",
      "    print eig_limit\n",
      "    \n",
      "    nbunch = [n for n,v in eig_centralities.items() if v < eig_limit]\n",
      "    cg = nx_g.subgraph(nbunch)\n",
      "    cg = convert_graph(cg, to=\"graphtool\")\n",
      "    \n",
      "    edges.append(cg.num_edges())\n",
      "    nodes.append(cg.num_vertices())\n",
      "    if nodes[-1] == 0: \n",
      "        break\n",
      "    \n",
      "    diameters.append(gt.pseudo_diameter(cg)[0])\n",
      "    \n",
      "    res = gt.max_independent_vertex_set(cg)\n",
      "    maxind_vertsets.append(propmap_len(cg.vertices(), res))\n",
      "    \n",
      "    res = gt.max_cardinality_matching(cg)\n",
      "    max_matches.append(sum(res[0].a))\n",
      "    \n",
      "    lap = gt.laplacian(cg)\n",
      "    eig_vals = np.linalg.eigvals(lap.todense())\n",
      "    eig_vals = sort(eig_vals)\n",
      "    alg_conn.append(eig_vals[1])\n",
      "    \n",
      "    min_cut.append(gt.min_cut(cg, cg.edge_properties[\"weight\"])[0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "min_cut = []\n",
      "clust_coeff = []\n",
      "clust_coeff_std = []\n",
      "for eig_limit in eig_limits:\n",
      "    print eig_limit,\n",
      "    nbunch = [n for n,v in eig_centralities.items() if v < eig_limit]\n",
      "    cg = nx_g.subgraph(nbunch)\n",
      "    for u,v,d in cg.edges(data=True):\n",
      "        d[\"weight\"] = 1\n",
      "    cg = convert_graph(cg, to=\"graphtool\")\n",
      "    \n",
      "    clust_coeff.append(gt.global_clustering(cg)[0])\n",
      "    clust_coeff_std.append(gt.global_clustering(cg)[1])\n",
      "    \n",
      "    #res = gt.min_cut(cg, cg.edge_properties[\"weight\"])[0]\n",
      "    #min_cut.append(res)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "nbunch = [n for n,v in eig_centralities.items() if v < 0.001]\n",
      "cg = nx_g.subgraph(nbunch)\n",
      "for u,v,d in cg.edges(data=True):\n",
      "    d[\"weight\"] = 1\n",
      "print cg.number_of_nodes(), cg.number_of_edges()\n",
      "\n",
      "cg = convert_graph(cg)\n",
      "print cg.num_vertices(), cg.num_edges()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for e in cg.edges():\n",
      "    print e, cg.edge_properties[\"weight\"][e]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "res = gt.min_cut(cg, cg.edge_properties[\"weight\"])\n",
      "for v in cg.vertices():\n",
      "    if res[1][v]:\n",
      "        print v"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "y = min_cut\n",
      "\n",
      "#res = zip(eig_limits, y)\n",
      "#res = array(sorted(res, key=lambda x:x[0]))\n",
      "#plot(res[:, 0], res[:, 1])\n",
      "\n",
      "plot(eig_limits, y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "nx.write_graphml(cg, \"/homedtic/gkoduri/workspace/relation-extraction/data/carnatic_link_graph_0.1_cg.graphml\", \n",
      "                 encoding=\"utf-8\")\n",
      "nx.write_graphml(central_g, \"/homedtic/gkoduri/workspace/relation-extraction/data/carnatic_link_graph_0.1_central_g.graphml\", \n",
      "                 encoding=\"utf-8\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##2. Community detection\n",
      "\n",
      "* Get the communities from the graph, setting a constraint of minimum number of nodes per community."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "curg = cg\n",
      "partition = c.best_partition(curg)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "categories = {}\n",
      "min_com_size = 10\n",
      "\n",
      "for com in set(partition.values()) :\n",
      "    list_nodes = [nodes for nodes in partition.keys()\n",
      "                                if partition[nodes] == com]\n",
      "    print com, len(list_nodes)\n",
      "    print\n",
      "    if len(list_nodes) > min_com_size:\n",
      "         categories[com] = list_nodes"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###2.1 Cleaning with the help of central nodes"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for ind, com in categories.items():\n",
      "    print ind, len(com), len(set(central_nodes).intersection(com))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ind = 0\n",
      "print set(central_nodes).intersection(categories[ind])\n",
      "print\n",
      "print categories[ind]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###2.2 Center and periphery stuff"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "nbunches = []\n",
      "for com, category in categories.items():\n",
      "    subg = cg.subgraph(category)\n",
      "    \n",
      "    res = nx.center(subg)\n",
      "    nodes = [i for i in res]\n",
      "    nbunches.append(nodes)\n",
      "    print len(category), len(nodes),\n",
      "    \n",
      "    res = nx.periphery(subg)\n",
      "    nodes = [i  for i in res]\n",
      "    nbunches.append(nodes)\n",
      "    print len(nodes)\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for com, nbunch in categories.items():\n",
      "    avg_cc = nx.average_clustering(curg, nbunch)\n",
      "    \n",
      "    subg = nx.subgraph(curg, nbunch)\n",
      "    sub_cc = nx.average_clustering(subg)\n",
      "    \n",
      "    print len(nbunch), avg_cc, sub_cc"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for nbunch in nbunches:\n",
      "    avg_cc = nx.average_clustering(curg, nbunch)\n",
      "    \n",
      "    subg = nx.subgraph(curg, nbunch)\n",
      "    sub_cc = nx.average_clustering(subg)\n",
      "    \n",
      "    print len(nbunch), avg_cc, sub_cc"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for nbunch in nbunches:\n",
      "    print len(nbunch), nbunch\n",
      "    print"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print len(nodes)\n",
      "for com, nodes_com in categories.items():\n",
      "    print len(nodes_com),\n",
      "    res = set(nodes).intersection(nodes_com)\n",
      "    print len(res)\n",
      "    #res = set(nodes_com) - res\n",
      "    #print np.median([node_connectivities[i] for i in res if i in node_connectivities.keys()])\n",
      "    print res"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for ind, com in categories.items():\n",
      "    print ind, np.mean([node_reverse_connectivities[i] for i in com]), com\n",
      "    #print ind, [node_reverse_connectivities[i] for i in com]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Draw the partitions"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def plot_communities(g, partition):\n",
      "    colors = [\"#00308F\", \"#AF002A\", \"#FF7E00\", \"#665D1E\", \"#841B2D\", \"#3D2B1F\", \"#79443B\", \"#CD7F32\", \"#7FFF00\", \n",
      "              \"#893F45\", \"#9400D3\", \"#9B7653\", \"#555D50\", \"#CD5C5C\", \"#EE82EE\"]\n",
      "    \n",
      "    size = float(len(set(partition.values())))\n",
      "    pos = nx.spring_layout(g)\n",
      "    count = 0\n",
      "    for com in set(partition.values()) :\n",
      "        count = count + 1\n",
      "        list_nodes = [nodes for nodes in partition.keys()\n",
      "                                    if partition[nodes] == com]\n",
      "        nx.draw_networkx_nodes(g, pos, list_nodes, node_size = 20,\n",
      "                                    node_color = colors[count-1])\n",
      "    \n",
      "    \n",
      "    nx.draw_networkx_edges(g, pos, alpha=0.5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def filter_nodes(g, min_com_size=25):\n",
      "    partition = c.best_partition(g)\n",
      "    communities = {}\n",
      "    \n",
      "    for com in set(partition.values()) :\n",
      "        list_nodes = [nodes for nodes in partition.keys()\n",
      "                                    if partition[nodes] == com]\n",
      "        if len(list_nodes) > min_com_size:\n",
      "             communities[com] = list_nodes\n",
      "    \n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Shortest path algorithm\n",
      "#Note: Does not give a good result!\n",
      "\n",
      "nodes = [\"t. m. krishna\", \"abhogi\", \"vijayanagara musicological nonet\", \"chennai\", \n",
      "         \"azam jah of the carnatic\", \"mazhavaraayas\", \"national indian music competition\", \n",
      "         \"ceylon defence force\", \"madanakamarajan\", \"gaadha\"]\n",
      "\n",
      "target_node = \"carnatic music\"\n",
      "thresh = 0.3\n",
      "\n",
      "for src_node in nodes:\n",
      "    print src_node\n",
      "    paths = nx.shortest_paths.all_shortest_paths(g, src_node, target_node)\n",
      "    #paths = nx.simple_paths.all_simple_paths(g, src_node, target_node, cutoff=2)\n",
      "    \n",
      "    relevance = 0\n",
      "    count = 0\n",
      "    for path in paths:\n",
      "        #print path, \n",
      "        l = len(path)\n",
      "        count += 1\n",
      "        weights = []\n",
      "        for i in xrange(l-1):\n",
      "            edge_data = g.get_edge_data(path[i], path[i+1])\n",
      "            if type(edge_data) is dict:\n",
      "                weights.append(edge_data[\"weight\"])\n",
      "        \n",
      "        w = reduce(lambda x, y: x*y, weights)\n",
      "        relevance += w/(l*l)\n",
      "        #print weights, w/len(path)\n",
      "    relevance /= count\n",
      "    print \"Total relevance\", relevance, \"\\n\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}
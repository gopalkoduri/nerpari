{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "For all the pythonic graph modifications, we use networkx as it is easy! On the other hand, graph-tool is completely written in C++ and is orders of magnitude faster than networkx. So we use it for computations on graphs."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from __future__ import division\n",
      "\n",
      "import graph_tool.all as gt\n",
      "import networkx as nx\n",
      "import community as c\n",
      "import pickle\n",
      "from pylab import *\n",
      "\n",
      "%matplotlib tk\n",
      "#rcParams['figure.figsize'] = 16, 12"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "annotations = pickle.load(file('/homedtic/gkoduri/workspace/relation-extraction/data/annotations.pickle'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fname = '/homedtic/gkoduri/workspace/relation-extraction/data/carnatic_hyperlinks.graphml'\n",
      "nx_g = nx.read_graphml(fname, node_type=unicode)\n",
      "print nx_g.number_of_nodes(), nx_g.number_of_edges()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1450 8668\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Some housekeeping functions"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import cStringIO\n",
      "\n",
      "def propmap_len(vertices, propmap):\n",
      "    count = 0\n",
      "    for v in vertices:\n",
      "        if propmap[v]:\n",
      "            count += 1\n",
      "    return count\n",
      "\n",
      "def convert_graph(src_g, to=\"graphtool\"):\n",
      "    buf = cStringIO.StringIO()\n",
      "    if to == \"graphtool\":\n",
      "        nx.write_graphml(src_g, buf, encoding='utf-8')\n",
      "        buf.flush()\n",
      "        buf.reset()\n",
      "        dest_g = gt.Graph()\n",
      "        dest_g.load(buf, fmt=\"xml\")\n",
      "    else:\n",
      "        src_g.save(buf, fmt=\"xml\")\n",
      "        buf.flush()\n",
      "        buf.reset()\n",
      "        dest_g = nx.read_graphml(buf, node_type=unicode)\n",
      "    return dest_g\n",
      "\n",
      "def sample_graph(g, num_nodes=100):\n",
      "    nodes = array(g.nodes())\n",
      "    indices = unique(random_integers(0, len(nodes), num_nodes+100))[:num_nodes]\n",
      "    nodes = nodes[indices]\n",
      "    sub_graph = g.subgraph(nodes)\n",
      "    return sub_graph\n",
      "\n",
      "def filter_edgeweight(g, thresh, weight_type=\"distance\"):\n",
      "    filt_g = g.copy()\n",
      "    for u,v,d in filt_g.edges(data=True):\n",
      "        if weight_type == \"distance\":\n",
      "            if d[\"weight\"] > thresh:\n",
      "                filt_g.remove_edge(u,v)\n",
      "        elif weight_type == \"similarity\":\n",
      "            if d[\"weight\"] < thresh:\n",
      "                filt_g.remove_edge(u,v)\n",
      "                \n",
      "    nodes = filt_g.nodes()\n",
      "    for n in nodes:\n",
      "        if filt_g.degree(n) == 0:\n",
      "            filt_g.remove_node(n)\n",
      "        \n",
      "    return filt_g"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Invert weights\n",
      "Weights in our graphs convey similarity. But they should mean 'distances' in graph theory"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for u,v,d in nx_g.edges(data=True):\n",
      "    d[\"weight\"] = 1.0-d[\"weight\"]+0.000001"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Filter edges"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "filt_g = filter_edgeweight(nx_g, 0.8, weight_type=\"distance\")\n",
      "print filt_g.number_of_nodes(), filt_g.number_of_edges()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Convert to graph-tool format"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "gt_g = convert_graph(filt_g)\n",
      "print gt_g.num_vertices(), gt_g.num_edges()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Random sample a graph"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sub_g = sample_graph(filt_g, 200)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "nx.write_graphml(sub_g, \"/homedtic/gkoduri/workspace/relation-extraction/data/carnatic_unigrams_sample.graphml\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Shortest path filter\n",
      "\n",
      "**Results:** Jus the shortest path filter alone gets upto 0.57 of precision with 0.57 share of nodes. Not enough, but not bad."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ug = nx_g.to_undirected()\n",
      "target_node = \"carnatic music\"\n",
      "shortest_path_lenghts = nx.shortest_path_length(ug, target=target_node, weight=\"weight\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "x = []\n",
      "n = []\n",
      "precisions = []\n",
      "recalls = []\n",
      "f_measures = []\n",
      "path_lengths = np.arange(0, 5, 1)\n",
      "\n",
      "for path_length in path_lengths:\n",
      "    tp = 0.0\n",
      "    tn = 0.0\n",
      "    fp = 0.0\n",
      "    fn = 0.0\n",
      "\n",
      "    nodes = []\n",
      "    for i in ug.nodes_iter():\n",
      "        if i in shortest_path_lenghts.keys() and shortest_path_lenghts[i] < path_length:\n",
      "            nodes.append(i)\n",
      "    \n",
      "    if len(nodes) < 50:\n",
      "        continue\n",
      "        \n",
      "    x.append(path_length)\n",
      "    n.append(len(nodes))\n",
      "    for page, category in annotations.items():\n",
      "        if page in nodes:\n",
      "            if category == \"carnatic\":\n",
      "                tp += 1\n",
      "            else:\n",
      "                fp += 1\n",
      "        else:\n",
      "            if category == \"carnatic\":\n",
      "                fn += 1\n",
      "            else:\n",
      "                tn += 1\n",
      "    precisions.append(tp/(tp+fp))\n",
      "    recalls.append(tp/(tp+fn))\n",
      "    f_measures.append(2*tp/(2*tp+fp+fn))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#plot(x, num_nodes, label=\"Number of nodes\")\n",
      "plot(x, f_measures, label=\"F-measure\")\n",
      "plot(x, precisions, label=\"Precision\")\n",
      "plot(x, recalls, label=\"Recall\")\n",
      "\n",
      "legend()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 17,
       "text": [
        "<matplotlib.legend.Legend at 0x5953650>"
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Degree filter\n",
      "\n",
      "**Result:** Just the degree does not help with the precision at all, it never crosses 0.4!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#degrees = nx.degree(filt_g, weight=\"weight\")\n",
      "degrees = nx.degree(ug)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "x = []\n",
      "n = []\n",
      "precisions = []\n",
      "recalls = []\n",
      "f_measures = []\n",
      "path_lengths = np.arange(min(degrees.values()), max(degrees.values()), 1)\n",
      "all_nodes = ug.nodes()\n",
      "\n",
      "for path_length in path_lengths:\n",
      "    tp = 0.0\n",
      "    tn = 0.0\n",
      "    fp = 0.0\n",
      "    fn = 0.0\n",
      "\n",
      "    nodes = []\n",
      "    for i in all_nodes:\n",
      "        if i in degrees.keys() and degrees[i] < path_length:\n",
      "            nodes.append(i)\n",
      "    \n",
      "    if len(nodes) < 50:\n",
      "        continue\n",
      "        \n",
      "    x.append(path_length)\n",
      "    n.append(len(nodes))\n",
      "    for page, category in annotations.items():\n",
      "        if page in nodes:\n",
      "            if category == \"carnatic\":\n",
      "                tp += 1\n",
      "            else:\n",
      "                fp += 1\n",
      "        else:\n",
      "            if category == \"carnatic\":\n",
      "                fn += 1\n",
      "            else:\n",
      "                tn += 1\n",
      "    precisions.append(tp/(tp+fp))\n",
      "    recalls.append(tp/(tp+fn))\n",
      "    f_measures.append(2*tp/(2*tp+fp+fn))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#plot(x, num_nodes, label=\"Number of nodes\")\n",
      "plot(x, f_measures, label=\"F-measure\")\n",
      "plot(x, precisions, label=\"Precision\")\n",
      "plot(x, recalls, label=\"Recalls\")\n",
      "\n",
      "legend()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 21,
       "text": [
        "<matplotlib.legend.Legend at 0x5cb3f10>"
       ]
      }
     ],
     "prompt_number": 21
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Pagerank filter on hyperlinks graph\n",
      "**Results**: The precision won't go beyond 0.5, even then the number of nodes are too low."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pageranks = nx.pagerank(filt_g)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pos = [k for k,v in annotations.items() if v == \"carnatic\"]\n",
      "neg = [k for k,v in annotations.items() if v == \"non-carnatic\"]\n",
      "\n",
      "print sum([pageranks[n] for n in pos if n in pageranks.keys()])/len(pos)\n",
      "print sum([pageranks[n] for n in neg if n in pageranks.keys()])/len(neg)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "n = []\n",
      "precisions = []\n",
      "recalls = []\n",
      "f_measures = []\n",
      "eig_limits = np.arange(0.0001, 0.001, 0.0001)\n",
      "\n",
      "for eig_limit in eig_limits:\n",
      "    tp = 0.0\n",
      "    tn = 0.0\n",
      "    fp = 0.0\n",
      "    fn = 0.0\n",
      "\n",
      "    nodes = [i for i in filt_g.nodes_iter() if pageranks[i] > eig_limit]\n",
      "    \n",
      "    if len(nodes) <= 50:\n",
      "        break\n",
      "        \n",
      "    n.append(len(nodes))\n",
      "    for page, category in annotations.items():\n",
      "        if page in nodes:\n",
      "            if category == \"carnatic\":\n",
      "                tp += 1\n",
      "            else:\n",
      "                fp += 1\n",
      "        else:\n",
      "            if category == \"carnatic\":\n",
      "                fn += 1\n",
      "            else:\n",
      "                tn += 1\n",
      "    precisions.append(tp/(tp+fp))\n",
      "    recalls.append(tp/(tp+fn))\n",
      "    f_measures.append(2*tp/(2*tp+fp+fn))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "num_nodes = np.array(n)/nx_g.number_of_nodes()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "x = eig_limits[:len(num_nodes)]\n",
      "\n",
      "plot(x, num_nodes, label=\"Number of nodes\")\n",
      "plot(x, f_measures, label=\"F-measure\")\n",
      "plot(x, precisions, label=\"Precision\")\n",
      "plot(x, recalls, label=\"Recalls\")\n",
      "\n",
      "legend()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Eigenvector centrality filter\n",
      "**Results**: The precision and f-measure peak at 0.6 with 0.4 share of total nodes"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "eig_data = gt.eigenvector(gt_g, weight=gt_g.edge_properties[\"weight\"])\n",
      "#eig_data[0] is the largest eigenvalue of weighted adjacency matrix\n",
      "#eig_data[1] has the vertex property map with eigenvector centralities for each vertex\n",
      "print eig_data[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#covert the eig values to be used easily with networkx\n",
      "gt_labelmap = gt_g.vertex_properties['_graphml_vertex_id']\n",
      "eig_centralities = {}\n",
      "for v in gt_g.vertices():\n",
      "    eig_centralities[gt_labelmap[v].decode('utf-8')] = eig_data[1][v]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* **Just have a look at some values!**"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pos = [k for k,v in annotations.items() if v == \"carnatic\"]\n",
      "neg = [k for k,v in annotations.items() if v == \"non-carnatic\"]\n",
      "\n",
      "print sum([eig_centralities[n] for n in pos if n in eig_centralities.keys()])/len(pos)\n",
      "print sum([eig_centralities[n] for n in neg if n in eig_centralities.keys()])/len(neg)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* **Plot how the number of relations per node varies as we keep increasing the eig_centrality threshold to remove spurious nodes.** "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tempg = nx_g.copy()\n",
      "eig_limits = np.arange(0.0001, 0.1, 0.0003)\n",
      "edges = []\n",
      "nodes = []\n",
      "y = []\n",
      "for eig_limit in eig_limits:\n",
      "    nbunch = [n for n,v in eig_centralities.items() if v < eig_limit]\n",
      "    tempg.remove_nodes_from(nbunch)\n",
      "    \n",
      "    edges.append(tempg.number_of_edges())\n",
      "    nodes.append(tempg.number_of_nodes())\n",
      "    if nodes[-1] == 0: break\n",
      "    y.append(1.0*edges[-1]/nodes[-1])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plot(eig_limits[:len(y)], y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* **Get the eig_value corresponding to the peak in that plot.**\n",
      "* **Get the nodes setting that eig_value as threshold. These are the nodes which we are most confident are relevant!**"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "thresh = 0.02\n",
      "nodes = [i for i in filt_g.nodes_iter() if eig_centralities[i] > thresh]\n",
      "central_nodes = nodes\n",
      "print len(central_nodes)\n",
      "central_nodes"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Evalution of eigenvector centrality's performance"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "n = []\n",
      "precisions = []\n",
      "recalls = []\n",
      "f_measures = []\n",
      "eig_limits = np.arange(0.00001, 0.5, 0.00003)\n",
      "\n",
      "for eig_limit in eig_limits:\n",
      "    tp = 0.0\n",
      "    tn = 0.0\n",
      "    fp = 0.0\n",
      "    fn = 0.0\n",
      "\n",
      "    nodes = [i for i in filt_g.nodes_iter() if eig_centralities[i] > eig_limit]\n",
      "    \n",
      "    if len(nodes) <= 50:\n",
      "        break\n",
      "        \n",
      "    n.append(len(nodes))\n",
      "    for page, category in annotations.items():\n",
      "        if page in nodes:\n",
      "            if category == \"carnatic\":\n",
      "                tp += 1\n",
      "            else:\n",
      "                fp += 1\n",
      "        else:\n",
      "            if category == \"carnatic\":\n",
      "                fn += 1\n",
      "            else:\n",
      "                tn += 1\n",
      "    precisions.append(tp/(tp+fp))\n",
      "    recalls.append(tp/(tp+fn))\n",
      "    f_measures.append(2*tp/(2*tp+fp+fn))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "n = array(n)/nx_g.number_of_nodes()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "figure()\n",
      "x = eig_limits[:len(n)]\n",
      "\n",
      "plot(x, n, label=\"Number of nodes\")\n",
      "plot(x, f_measures, label=\"F-measure\")\n",
      "plot(x, precisions, label=\"Precision\")\n",
      "plot(x, recalls, label=\"Recalls\")\n",
      "\n",
      "legend()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Different properties of graph to know its structure\n",
      "\n",
      "**What are the properties of the graph with only these central nodes, and how do they compare to the original graph?**\n",
      "\n",
      "* Diameter (nx.diameter)\n",
      "* Size (number of edges)\n",
      "* Clustering coefficient (nx.average_clustering)\n",
      "* Maximal independent set (nx.maximal_independent_set) --> *needs to be run multiple times and an average taken*\n",
      "* Clique number (nx.clique.graph_clique_number)\n",
      "* Algebraic connectivity (Second smallest eigen value of laplacian matrix of g)\n",
      "* Cheeger constant (TODO)\n",
      "* Minimum node/edge cut (nx.minimum_edge_cut or nx.minimum_node_cut)\n",
      "* Matchings (nx.matching.maximal_matching)\n",
      "* Estrada index (nx.estrada_index)\n",
      "* Vertex cover (networkx_approximate.py)\n",
      "\n",
      "\n",
      "**Other measures that can be considered when adding less good nodes to central nodes:**\n",
      "\n",
      "* Closeness vitality (related to weiner index, nx.closeness_vitality) --> *Is too slow!*"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cg = nx_g.subgraph(nodes)\n",
      "cg = convert_graph(cg)\n",
      "\n",
      "central_g = nx_g.subgraph(central_nodes)\n",
      "central_g = convert_graph(central_g)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Diameter**"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "res_central = gt.pseudo_diameter(central_g)\n",
      "res_ext = gt.pseudo_diameter(cg)\n",
      "res_all = gt.pseudo_diameter(gt_g)\n",
      "print res_central[0], res_ext[0], res_all[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Maximal independent vertex set**"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "res = gt.max_independent_vertex_set(central_g)\n",
      "print propmap_len(central_g.vertices(), res)\n",
      "\n",
      "res = gt.max_independent_vertex_set(cg)\n",
      "print propmap_len(cg.vertices(), res)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Maximal matching**"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "res = gt.max_cardinality_matching(central_g)\n",
      "#print propmap_len(central_g.edges(), res)\n",
      "print sum(res[0].a)\n",
      "\n",
      "res = gt.max_cardinality_matching(cg)\n",
      "print sum(res[0].a)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Algebraic connectivity**"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lap = gt.laplacian(central_g)\n",
      "eig_vals = np.linalg.eigvals(lap.todense())\n",
      "eig_vals = sort(eig_vals)\n",
      "print eig_vals[1],\n",
      "\n",
      "lap = gt.laplacian(cg)\n",
      "eig_vals = np.linalg.eigvals(lap.todense())\n",
      "eig_vals = sort(eig_vals)\n",
      "print eig_vals[1]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Min cut**"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print gt.min_cut(central_g, central_g.edge_properties[\"weight\"])[0] #, len(nx.minimum_edge_cut(cg))\n",
      "print gt.min_cut(cg, cg.edge_properties[\"weight\"])[0] #, len(nx.minimum_node_cut(cg))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Plot how all these measures vary as the number of nodes are increased**"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "eig_limits = np.arange(0.025, 0.0001, -0.0003)\n",
      "edges = []\n",
      "nodes = []\n",
      "diameters = []\n",
      "maxind_vertsets = []\n",
      "max_matches = []\n",
      "alg_conn = []\n",
      "min_cut = []\n",
      "\n",
      "for eig_limit in eig_limits:\n",
      "    print eig_limit\n",
      "    \n",
      "    nbunch = [n for n,v in eig_centralities.items() if v < eig_limit]\n",
      "    cg = nx_g.subgraph(nbunch)\n",
      "    cg = convert_graph(cg, to=\"graphtool\")\n",
      "    \n",
      "    edges.append(cg.num_edges())\n",
      "    nodes.append(cg.num_vertices())\n",
      "    if nodes[-1] == 0: \n",
      "        break\n",
      "    \n",
      "    diameters.append(gt.pseudo_diameter(cg)[0])\n",
      "    \n",
      "    res = gt.max_independent_vertex_set(cg)\n",
      "    maxind_vertsets.append(propmap_len(cg.vertices(), res))\n",
      "    \n",
      "    res = gt.max_cardinality_matching(cg)\n",
      "    max_matches.append(sum(res[0].a))\n",
      "    \n",
      "    lap = gt.laplacian(cg)\n",
      "    eig_vals = np.linalg.eigvals(lap.todense())\n",
      "    eig_vals = sort(eig_vals)\n",
      "    alg_conn.append(eig_vals[1])\n",
      "    \n",
      "    min_cut.append(gt.min_cut(cg, cg.edge_properties[\"weight\"])[0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "min_cut = []\n",
      "clust_coeff = []\n",
      "clust_coeff_std = []\n",
      "for eig_limit in eig_limits:\n",
      "    print eig_limit,\n",
      "    nbunch = [n for n,v in eig_centralities.items() if v < eig_limit]\n",
      "    cg = nx_g.subgraph(nbunch)\n",
      "    for u,v,d in cg.edges(data=True):\n",
      "        d[\"weight\"] = 1\n",
      "    cg = convert_graph(cg, to=\"graphtool\")\n",
      "    \n",
      "    clust_coeff.append(gt.global_clustering(cg)[0])\n",
      "    clust_coeff_std.append(gt.global_clustering(cg)[1])\n",
      "    \n",
      "    #res = gt.min_cut(cg, cg.edge_properties[\"weight\"])[0]\n",
      "    #min_cut.append(res)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "nbunch = [n for n,v in eig_centralities.items() if v < 0.001]\n",
      "cg = nx_g.subgraph(nbunch)\n",
      "for u,v,d in cg.edges(data=True):\n",
      "    d[\"weight\"] = 1\n",
      "print cg.number_of_nodes(), cg.number_of_edges()\n",
      "\n",
      "cg = convert_graph(cg)\n",
      "print cg.num_vertices(), cg.num_edges()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for e in cg.edges():\n",
      "    print e, cg.edge_properties[\"weight\"][e]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "res = gt.min_cut(cg, cg.edge_properties[\"weight\"])\n",
      "for v in cg.vertices():\n",
      "    if res[1][v]:\n",
      "        print v"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "y = min_cut\n",
      "\n",
      "#res = zip(eig_limits, y)\n",
      "#res = array(sorted(res, key=lambda x:x[0]))\n",
      "#plot(res[:, 0], res[:, 1])\n",
      "\n",
      "plot(eig_limits, y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "nx.write_graphml(cg, \"/homedtic/gkoduri/workspace/relation-extraction/data/carnatic_link_graph_0.1_cg.graphml\", \n",
      "                 encoding=\"utf-8\")\n",
      "nx.write_graphml(central_g, \"/homedtic/gkoduri/workspace/relation-extraction/data/carnatic_link_graph_0.1_central_g.graphml\", \n",
      "                 encoding=\"utf-8\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Filtering by communities\n",
      "\n",
      "* Get the communities from the graph, setting a constraint of minimum number of nodes per community."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "nodes = annotations.keys()\n",
      "sub_g = nx_g.subgraph(nodes)\n",
      "print sub_g.number_of_nodes(), sub_g.number_of_edges()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#sub_g = filter_edgeweight(sub_g, 0.9)\n",
      "#print sub_g.number_of_nodes(), sub_g.number_of_edges()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "curg = sub_g.copy()\n",
      "print curg.number_of_nodes(), curg.number_of_edges()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "partition = c.best_partition(curg)\n",
      "print len(np.unique(partition.values()))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "categories = {}\n",
      "min_com_size = 10\n",
      "\n",
      "for com in set(partition.values()) :\n",
      "    list_nodes = [nodes for nodes in partition.keys()\n",
      "                                if partition[nodes] == com]\n",
      "    print com, len(list_nodes)\n",
      "    print\n",
      "    if len(list_nodes) > min_com_size:\n",
      "         categories[com] = list_nodes"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for com, nbunch in categories.items():\n",
      "    print com, len(nbunch), np.sort(nbunch)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###2.1 Cleaning with the help of a graph metric"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Avg shortest path to Carntic music\n",
      "src_node = \"carnatic music\"\n",
      "\n",
      "for com, nbunch in categories.items():\n",
      "    total_length = 0.0\n",
      "    no_path_count = 0\n",
      "    for dest_node in nbunch:\n",
      "        try:\n",
      "            total_length += nx.shortest_path_length(filt_g, src_node, dest_node, weight=\"weight\")\n",
      "        except:\n",
      "            no_path_count += 1\n",
      "            continue\n",
      "    \n",
      "    print com, len(nbunch), total_length/len(nbunch), no_path_count\n",
      "        "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#eigenvector centrality\n",
      "for com, nbunch in categories.items():\n",
      "    print com, len(nbunch), sum([ eig_centralities[n] for n in nbunch if n in eig_centralities.keys() ])/len(nbunch)\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#maximal independent set\n",
      "for com, nbunch in categories.items():\n",
      "    cg = curg.subgraph(nbunch)\n",
      "    cg = convert_graph(cg)\n",
      "    res = gt.max_independent_vertex_set(cg)\n",
      "    print com, len(nbunch), propmap_len(cg.vertices(), res), propmap_len(cg.vertices(), res)/len(nbunch)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for com, nbunch in categories.items():\n",
      "    cg = curg.subgraph(nbunch)\n",
      "    cg = convert_graph(cg)\n",
      "    res = gt.max_cardinality_matching(cg)\n",
      "    print com, len(nbunch), sum(res[0].a), sum(res[0].a)/len(nbunch)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#algebraic connectivity\n",
      "for com, nbunch in categories.items():\n",
      "    cg = curg.subgraph(nbunch)\n",
      "\n",
      "    #lap = gt.laplacian(cg)\n",
      "    #eig_vals = np.linalg.eigvals(lap.todense())\n",
      "    lap = nx.linalg.laplacian_matrix(cg)\n",
      "    eig_vals = np.linalg.eigvals(lap)\n",
      "    eig_vals = sort(eig_vals)\n",
      "    print com, len(nbunch), eig_vals[1]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for com, nbunch in categories.items():\n",
      "    cg = curg.subgraph(nbunch)\n",
      "    cg = convert_graph(cg)\n",
      "    print com, len(nbunch), round(gt.pseudo_diameter(cg, weights=cg.edge_properties[\"weight\"])[0], 2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Using disparity filter"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def filter_graph_edges(G, DISPARITY_FILTER_SIGNIF_LEVEL, verbose=False, print_prefix=''):\n",
      "\n",
      "    '''\n",
      "    A large number of complex systems find a natural abstraction in the form of weighted networks whose nodes represent\n",
      "    the elements of the system and the weighted edges identify the presence of an interaction and its relative strength.\n",
      "    In recent years, the study of an increasing number of large-scale networks has highlighted the statistical\n",
      "    heterogeneity of their interaction pattern, with degree and weight distributions that vary over many orders of\n",
      "    magnitude. These features, along with the large number of elements and links, make the extraction of the truly\n",
      "    relevant connections forming the network's backbone a very challenging problem. More specifically, coarse-graining\n",
      "    approaches and filtering techniques come into conflict with the multiscale nature of large-scale systems. Here, we\n",
      "    define a filtering method that offers a practical procedure to extract the relevant connection backbone in complex\n",
      "    multiscale networks, preserving the edges that represent statistically significant deviations with respect to a\n",
      "    null model for the local assignment of weights to edges. An important aspect of the method is that it does not\n",
      "    belittle small-scale interactions and operates at all scales defined by the weight distribution. We apply our\n",
      "    method to real-world network instances and compare the obtained results with alternative backbone\n",
      "    extraction techniques. (http://www.pnas.org/content/106/16/6483.abstract)\n",
      "    '''\n",
      "\n",
      "    if verbose:\n",
      "        print '%sFiltering with ' % print_prefix + str(100*(1-DISPARITY_FILTER_SIGNIF_LEVEL))+'% confidence ...',\n",
      "\n",
      "    # FOR DIRECTED\n",
      "    #indegree = G.in_degree(weight=None)\n",
      "    #outdegree = G.out_degree(weight=None)\n",
      "    #instrength = G.in_degree(weight='weight')\n",
      "    #outstrength = G.out_degree(weight='weight')\n",
      "\n",
      "    # FOR UNDIRECTED\n",
      "    degree = G.degree(weight=None)\n",
      "    strength = G.degree(weight='weight')\n",
      "\n",
      "    edges = G.edges()\n",
      "    for i, j in edges:\n",
      "            # FOR DIRECTED\n",
      "            #pij = float(G[i][j]['weight'])/float(outstrength[i])\n",
      "            #pji = float(G[i][j]['weight'])/float(instrength[j])\n",
      "            #aij = (1-pij)**(outdegree[i]-1)\n",
      "            #aji = (1-pji)**(indegree[j]-1)\n",
      "            #if aij < DISPARITY_FILTER_SIGNIF_LEVEL or aji < DISPARITY_FILTER_SIGNIF_LEVEL:\n",
      "            #    continue\n",
      "\n",
      "            # FOR UNDIRECTED\n",
      "            pij = float(G[i][j]['weight'])/float(strength[i])\n",
      "            aij = (1-pij)**(degree[i]-1)\n",
      "            if aij < DISPARITY_FILTER_SIGNIF_LEVEL:\n",
      "                continue\n",
      "\n",
      "            G.remove_edge(i, j)\n",
      "    nodes = G.nodes()\n",
      "    for n in nodes:\n",
      "        if G.degree(n) < 1:\n",
      "            #print n\n",
      "            G.remove_node(n)\n",
      "    if verbose:\n",
      "        print G.number_of_nodes(), 'nodes,', G.number_of_edges(), 'edges'\n",
      "\n",
      "    return G\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "precisions = []\n",
      "recalls = []\n",
      "f_measures = []\n",
      "\n",
      "disp_sig_levels = np.arange(0.01, 0.9, 0.01)\n",
      "\n",
      "for disp_sig_level in disp_sig_levels:\n",
      "    tp = 0.0\n",
      "    tn = 0.0\n",
      "    fp = 0.0\n",
      "    fn = 0.0\n",
      "\n",
      "    tempg = ug.copy()\n",
      "    filt_g = filter_graph_edges(tempg, disp_sig_level)\n",
      "\n",
      "    \n",
      "    nodes = filt_g.nodes()\n",
      "    for page, category in annotations.items():\n",
      "        if page in nodes:\n",
      "            if category == \"carnatic\":\n",
      "                tp += 1\n",
      "            else:\n",
      "                fp += 1\n",
      "        else:\n",
      "            if category == \"carnatic\":\n",
      "                fn += 1\n",
      "            else:\n",
      "                tn += 1\n",
      "    if tp > 0:\n",
      "        precisions.append(tp/(tp+fp))\n",
      "        recalls.append(tp/(tp+fn))\n",
      "        f_measures.append(2*tp/(2*tp+fp+fn))\n",
      "    else:\n",
      "        precisions.append(0)\n",
      "        recalls.append(0)\n",
      "        f_measures.append(0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "KeyError",
       "evalue": "'weight'",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-23-c51a2bb3dba7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mtempg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mug\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m     \u001b[0mfilt_g\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfilter_graph_edges\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtempg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdisp_sig_level\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m<ipython-input-22-17f5fddb8643>\u001b[0m in \u001b[0;36mfilter_graph_edges\u001b[1;34m(G, DISPARITY_FILTER_SIGNIF_LEVEL, verbose, print_prefix)\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m             \u001b[1;31m# FOR UNDIRECTED\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m             \u001b[0mpij\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mG\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'weight'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstrength\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m             \u001b[0maij\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mpij\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdegree\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0maij\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mDISPARITY_FILTER_SIGNIF_LEVEL\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mKeyError\u001b[0m: 'weight'"
       ]
      }
     ],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plot(disp_sig_levels, f_measures, label=\"F-measure\")\n",
      "plot(disp_sig_levels, precisions, label=\"Precision\")\n",
      "plot(disp_sig_levels, recalls, label=\"Recalls\")\n",
      "\n",
      "legend()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Draw the partitions"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def plot_communities(g, partition):\n",
      "    colors = [\"#00308F\", \"#AF002A\", \"#FF7E00\", \"#665D1E\", \"#841B2D\", \"#3D2B1F\", \"#79443B\", \"#CD7F32\", \"#7FFF00\", \n",
      "              \"#893F45\", \"#9400D3\", \"#9B7653\", \"#555D50\", \"#CD5C5C\", \"#EE82EE\"]\n",
      "    \n",
      "    size = float(len(set(partition.values())))\n",
      "    pos = nx.spring_layout(g)\n",
      "    count = 0\n",
      "    for com in set(partition.values()) :\n",
      "        count = count + 1\n",
      "        list_nodes = [nodes for nodes in partition.keys()\n",
      "                                    if partition[nodes] == com]\n",
      "        nx.draw_networkx_nodes(g, pos, list_nodes, node_size = 20,\n",
      "                                    node_color = colors[count-1])\n",
      "    \n",
      "    \n",
      "    nx.draw_networkx_edges(g, pos, alpha=0.5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}
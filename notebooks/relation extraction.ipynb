{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from os import chdir\n",
      "chdir(\"/homedtic/gkoduri/workspace/relation-extraction/src/\")\n",
      "code_dir = \"/homedtic/gkoduri/workspace/relation-extraction/\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import re\n",
      "import nltk\n",
      "import pickle\n",
      "import codecs\n",
      "import networkx as nx\n",
      "import wiki_indexer as wi\n",
      "import xml.etree.ElementTree as ET\n",
      "reload(wi)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 15,
       "text": [
        "<module 'wiki_indexer' from 'wiki_indexer.pyc'>"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Write the plain text content to disk"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "wiki_index = pickle.load(file('../data/wiki_index.pickle'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "g = nx.read_graphml('../data/carnatic_music_lsa_clean.graphml', node_type=unicode)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "res = g.nodes()\n",
      "for i in xrange(len(res)):\n",
      "    print i\n",
      "    print res[i].encode(\"ascii\")\n",
      "    #print i.encode(\"utf-8\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for page_title in g.nodes():\n",
      "    if page_title in wiki_index.keys():\n",
      "        content = wi.get_page_content(page_title, wiki_index)\n",
      "        codecs.open(code_dir+\"/data/content-analysis/carnatic_music/plain-text/\"+page_title.encode(\"utf-8\")+\".txt\", \"w\", \"utf-8\").write(content)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Tokenize each page to sentences"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sent_tokenizer = nltk.punkt.PunktSentenceTokenizer()\n",
      "all_sentences = []\n",
      "for page_title in g.nodes():\n",
      "    content = codecs.open(code_dir+\"/data/content-analysis/carnatic_music/plain-text/\"+page_title.encode(\"utf-8\")+\".txt\", \"r\", \"utf-8\").read()\n",
      "    nltk.punkt.PunktTrainer(content, verbose=True)\n",
      "    all_sentences.extend(sent_tokenizer.tokenize(content))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for i in xrange(len(all_sentences)):\n",
      "    all_sentences[i] = all_sentences[i].strip()\n",
      "    if \"\\n\" in all_sentences[i]:\n",
      "        parts = [(part, len(part)) for part in all_sentences[i].split(\"\\n\")]\n",
      "        parts = sorted(parts, key=lambda x: x[1], reverse=True)\n",
      "        all_sentences[i] = parts[0][0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "s_file = codecs.open(\"../data/content-analysis/carnatic_music/carnatic_music.sentences\", \"w\", \"utf-8\")\n",
      "all_sentences = [i+\"\\n\" for i in all_sentences]\n",
      "s_file.writelines(all_sentences)\n",
      "s_file.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Parsing the xml output from stanford-corenlp"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tree = ET.parse('../data/content-analysis/carnatic_music/stanford-nlp-output/bhavapriya.xml')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "root = tree.getroot()\n",
      "sentences = []\n",
      "for s in root.iter('sentence'):\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Parsing the output from reverb"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "relations = codecs.open('/mnt/compmusic/users/gkoduri/workspace/relation-extraction/data/content-analysis/carnatic_music/carnatic_music.relations_reverb',\n",
      "                    encoding='utf-8').readlines()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "f = codecs.open('../data/content-analysis/carnatic_music/carnatic_music.relations_reverb_andrea', 'w', 'utf-8')\n",
      "for rel_data in relations:\n",
      "    rel = rel_data.split('\\t')\n",
      "    f.write('\\t'.join(rel[-3:]))\n",
      "f.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Parsing the output from openie"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The output will have 6 fileds when split by a tab.\n",
      "\n",
      "0. Confidence score\n",
      "1. Context (i.e., condition or something that is like a reification)\n",
      "2. Argument 1\n",
      "3. Relation\n",
      "4. Argument 2, 3 ... (Simple/Spatial/Temporal)\n",
      "5. The entire input sentence"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "relations = codecs.open('/mnt/compmusic/users/gkoduri/workspace/relation-extraction/data/content-analysis/carnatic_music/carnatic_music.relations_openie',\n",
      "                    encoding='utf-8').readlines()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "arg_starts = ['SimpleArgument\\(', 'SpatialArgument\\(', 'TemporalArgument\\(']\n",
      "rel_start = 'Relation\\('\n",
      "end = ',List\\('\n",
      "\n",
      "f = codecs.open('../data/content-analysis/carnatic_music/carnatic_music.relations_openie_andrea', 'w', 'utf-8')\n",
      "\n",
      "for rel_data in relations:\n",
      "    rel_parts = rel_data.split('\\t')\n",
      "    \n",
      "    expr = arg_starts[0] + '(.*)' + end\n",
      "    arg1 = re.search(expr, rel_parts[2])\n",
      "    if arg1:\n",
      "        arg1 = arg1.group(1)\n",
      "    else:\n",
      "        continue\n",
      "    \n",
      "    expr = rel_start + '(.*)' + end\n",
      "    rel_string = re.search(expr, rel_parts[3])\n",
      "    if rel_string:\n",
      "        rel_string = rel_string.group(1)\n",
      "    else:\n",
      "        continue\n",
      "    \n",
      "    arg2 = []\n",
      "    temp = rel_parts[4].split(');')\n",
      "    for chunk in temp:\n",
      "        for arg_start in arg_starts:\n",
      "            expr = arg_start + '(.*)' + end\n",
      "            arg = re.search(expr, chunk)\n",
      "            if arg:\n",
      "                arg2.append(arg.group(1))\n",
      "            \n",
      "    for arg in arg2:\n",
      "        line = \"\\t\".join([arg1, rel_string, arg])+'\\n'\n",
      "        f.write(line)\n",
      "f.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 18
    }
   ],
   "metadata": {}
  }
 ]
}
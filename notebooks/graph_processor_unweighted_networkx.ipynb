{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Notebook for unweighted graph analysis"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Method\n",
      "\n",
      "1. Get the central nodes using eigenvector centralities.\n",
      "2. Remove the rubbish nodes that you are most confident of.\n",
      "2. Get communities from thus minimally cleaned graph.\n",
      "3. Further clean each community using the central nodes."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import networkx as nx\n",
      "import community as c\n",
      "import pickle\n",
      "%matplotlib inline\n",
      "rcParams['figure.figsize'] = 16, 12"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "g = nx.read_graphml(\"/homedtic/gkoduri/workspace/relation-extraction/data/carnatic_hyperlinks.graphml\", \n",
      "                    node_type=unicode)\n",
      "#g = g.to_undirected()\n",
      "print g.number_of_nodes(), g.number_of_edges()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1450 8668\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##1. Get the central nodes\n",
      "\n",
      "1. Plot how the number of relations per node varies as we keep increasing the eig_centrality threshold to remove spurious nodes. \n",
      "2. Get the eig_value corresponding to the peak in that plot.\n",
      "3. Get the nodes setting that eig_value as threshold. These are the nodes which we are most confident are relevant!\n",
      "4. Get another lower bound of that eig_value such that we can discard the nodes which we are most confident are rubbish!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "eig_centralities = nx.centrality.eigenvector_centrality(g)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Just have a look at some values!\n",
      "nodes = [\"m. s. subbulakshmi\", \"t. m. krishna\", \"carnatic wars\", \"abhogi\", \"telugu literature\", \n",
      "         \"s. p. balasubrahmanyam\"]\n",
      "print [(n, eig_centralities[n]) for n in nodes]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[('m. s. subbulakshmi', 0.038998225609287125), ('t. m. krishna', 0.030978993485476787), ('carnatic wars', 0.014604967494653457), ('abhogi', 0.030964846300106413), ('telugu literature', 0.03345425998885694), ('s. p. balasubrahmanyam', 0.055167640127530004)]\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* **Plot how the number of relations per node varies as we keep increasing the eig_centrality threshold to remove spurious nodes.** "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tempg = g.copy()\n",
      "eig_limits = np.arange(0.00001, 0.1, 0.0003)\n",
      "edges = []\n",
      "nodes = []\n",
      "y = []\n",
      "for eig_limit in eig_limits:\n",
      "    nbunch = [n for n,v in eig_centralities.items() if v < eig_limit]\n",
      "    tempg.remove_nodes_from(nbunch)\n",
      "    \n",
      "    edges.append(tempg.number_of_edges())\n",
      "    nodes.append(tempg.number_of_nodes())\n",
      "    y.append(1.0*edges[-1]/nodes[-1])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#figure()\n",
      "plot(eig_limits[:len(y)], y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* **Get the eig_value corresponding to the peak in that plot.**\n",
      "* **Get the nodes setting that eig_value as threshold. These are the nodes which we are most confident are relevant!**"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "thresh = 0.01\n",
      "nodes = [i for i in g.nodes_iter() if eig_centralities[i] > thresh]\n",
      "central_nodes = nodes\n",
      "print len(central_nodes)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* Get another lower bound of that eig_value such that we can discard the nodes which we are most confident are rubbish!\n",
      "\n",
      "    **TODO**: Automatically setting the bound"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "thresh = 0.001\n",
      "nodes = [i for i in g.nodes_iter() if eig_centralities[i] > thresh]\n",
      "cg = g.subgraph(nodes)\n",
      "print g.number_of_nodes(), g.number_of_edges()\n",
      "print cg.number_of_nodes(), cg.number_of_edges()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**How different is this bunch of nodes to the \"center\" of the graph?**\n",
      "\n",
      "Ans: In the first place, the graph needs to be connected for the \"center\" to be defined. Many versions of our graphs does not look like they are connected."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "res = nx.center(g)\n",
      "nodes = [i for i in res]\n",
      "print len(nodes), len(central_nodes), len(set(nodes).intersection(central_nodes))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**What are the properties of the graph with only these central nodes, and how do they compare to the original graph?**\n",
      "\n",
      "* Diameter (nx.diameter)\n",
      "* Size (number of edges)\n",
      "* Clustering coefficient (nx.average_clustering)\n",
      "* Maximal independent set (nx.maximal_independent_set) --> *needs to be run multiple times and an average taken*\n",
      "* Clique number (nx.clique.graph_clique_number)\n",
      "* Algebraic connectivity (Second smallest eigen value of laplacian matrix of g)\n",
      "* Cheeger constant (TODO)\n",
      "* Minimum node/edge cut (nx.minimum_edge_cut or nx.minimum_node_cut)\n",
      "* Matchings (nx.matching.maximal_matching)\n",
      "* Estrada index (nx.estrada_index)\n",
      "* Vertex cover (networkx_approximate.py)\n",
      "\n",
      "\n",
      "**Other measures that can be considered when adding less good nodes to central nodes:**\n",
      "\n",
      "* Closeness vitality (related to weiner index, nx.closeness_vitality) --> *Is too slow!*"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "central_g = g.subgraph(central_nodes)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print nx.diameter(central_g), nx.diameter(cg)\n",
      "print central_g.number_of_edges(), cg.number_of_edges()\n",
      "print nx.average_clustering(central_g), nx.average_clustering(cg)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "res = nx.maximal_independent_set(central_g)\n",
      "print (len([i for i in res])),\n",
      "res = nx.maximal_independent_set(cg)\n",
      "print (len([i for i in res]))\n",
      "\n",
      "print nx.graph_clique_number(central_g), nx.graph_clique_number(cg)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lap = nx.laplacian_matrix(central_g)\n",
      "eig_vals = np.linalg.eigvals(lap)\n",
      "eig_vals = sort(eig_vals)\n",
      "print eig_vals[1],\n",
      "\n",
      "lap = nx.laplacian_matrix(cg)\n",
      "eig_vals = np.linalg.eigvals(lap)\n",
      "eig_vals = sort(eig_vals)\n",
      "print eig_vals[1]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print len(nx.minimum_edge_cut(central_g)) #, len(nx.minimum_edge_cut(cg))\n",
      "print len(nx.minimum_node_cut(central_g)) #, len(nx.minimum_node_cut(cg))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print len(nx.maximal_matching(cg)), len(nx.maximal_matching(central_g))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "nx.write_graphml(cg, \"/homedtic/gkoduri/workspace/relation-extraction/data/carnatic_link_graph_0.1_cg.graphml\", \n",
      "                 encoding=\"utf-8\")\n",
      "nx.write_graphml(central_g, \"/homedtic/gkoduri/workspace/relation-extraction/data/carnatic_link_graph_0.1_central_g.graphml\", \n",
      "                 encoding=\"utf-8\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##2. Community detection\n",
      "\n",
      "* Get the communities from the graph, setting a constraint of minimum number of nodes per community."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "curg = cg\n",
      "partition = c.best_partition(curg)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "categories = {}\n",
      "min_com_size = 10\n",
      "\n",
      "for com in set(partition.values()) :\n",
      "    list_nodes = [nodes for nodes in partition.keys()\n",
      "                                if partition[nodes] == com]\n",
      "    print com, len(list_nodes)\n",
      "    print\n",
      "    if len(list_nodes) > min_com_size:\n",
      "         categories[com] = list_nodes"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###2.1 Cleaning with the help of central nodes"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for ind, com in categories.items():\n",
      "    print ind, len(com), len(set(central_nodes).intersection(com))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ind = 0\n",
      "print set(central_nodes).intersection(categories[ind])\n",
      "print\n",
      "print categories[ind]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###2.2 Center and periphery stuff"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "nbunches = []\n",
      "for com, category in categories.items():\n",
      "    subg = cg.subgraph(category)\n",
      "    \n",
      "    res = nx.center(subg)\n",
      "    nodes = [i for i in res]\n",
      "    nbunches.append(nodes)\n",
      "    print len(category), len(nodes),\n",
      "    \n",
      "    res = nx.periphery(subg)\n",
      "    nodes = [i  for i in res]\n",
      "    nbunches.append(nodes)\n",
      "    print len(nodes)\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for com, nbunch in categories.items():\n",
      "    avg_cc = nx.average_clustering(curg, nbunch)\n",
      "    \n",
      "    subg = nx.subgraph(curg, nbunch)\n",
      "    sub_cc = nx.average_clustering(subg)\n",
      "    \n",
      "    print len(nbunch), avg_cc, sub_cc"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for nbunch in nbunches:\n",
      "    avg_cc = nx.average_clustering(curg, nbunch)\n",
      "    \n",
      "    subg = nx.subgraph(curg, nbunch)\n",
      "    sub_cc = nx.average_clustering(subg)\n",
      "    \n",
      "    print len(nbunch), avg_cc, sub_cc"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for nbunch in nbunches:\n",
      "    print len(nbunch), nbunch\n",
      "    print"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print len(nodes)\n",
      "for com, nodes_com in categories.items():\n",
      "    print len(nodes_com),\n",
      "    res = set(nodes).intersection(nodes_com)\n",
      "    print len(res)\n",
      "    #res = set(nodes_com) - res\n",
      "    #print np.median([node_connectivities[i] for i in res if i in node_connectivities.keys()])\n",
      "    print res"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for ind, com in categories.items():\n",
      "    print ind, np.mean([node_reverse_connectivities[i] for i in com]), com\n",
      "    #print ind, [node_reverse_connectivities[i] for i in com]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Draw the partitions"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def plot_communities(g, partition):\n",
      "    colors = [\"#00308F\", \"#AF002A\", \"#FF7E00\", \"#665D1E\", \"#841B2D\", \"#3D2B1F\", \"#79443B\", \"#CD7F32\", \"#7FFF00\", \n",
      "              \"#893F45\", \"#9400D3\", \"#9B7653\", \"#555D50\", \"#CD5C5C\", \"#EE82EE\"]\n",
      "    \n",
      "    size = float(len(set(partition.values())))\n",
      "    pos = nx.spring_layout(g)\n",
      "    count = 0\n",
      "    for com in set(partition.values()) :\n",
      "        count = count + 1\n",
      "        list_nodes = [nodes for nodes in partition.keys()\n",
      "                                    if partition[nodes] == com]\n",
      "        nx.draw_networkx_nodes(g, pos, list_nodes, node_size = 20,\n",
      "                                    node_color = colors[count-1])\n",
      "    \n",
      "    \n",
      "    nx.draw_networkx_edges(g, pos, alpha=0.5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def filter_nodes(g, min_com_size=25):\n",
      "    partition = c.best_partition(g)\n",
      "    communities = {}\n",
      "    \n",
      "    for com in set(partition.values()) :\n",
      "        list_nodes = [nodes for nodes in partition.keys()\n",
      "                                    if partition[nodes] == com]\n",
      "        if len(list_nodes) > min_com_size:\n",
      "             communities[com] = list_nodes\n",
      "    \n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Shortest path algorithm\n",
      "#Note: Does not give a good result!\n",
      "\n",
      "nodes = [\"t. m. krishna\", \"abhogi\", \"vijayanagara musicological nonet\", \"chennai\", \n",
      "         \"azam jah of the carnatic\", \"mazhavaraayas\", \"national indian music competition\", \n",
      "         \"ceylon defence force\", \"madanakamarajan\", \"gaadha\"]\n",
      "\n",
      "target_node = \"carnatic music\"\n",
      "thresh = 0.3\n",
      "\n",
      "for src_node in nodes:\n",
      "    print src_node\n",
      "    paths = nx.shortest_paths.all_shortest_paths(g, src_node, target_node)\n",
      "    #paths = nx.simple_paths.all_simple_paths(g, src_node, target_node, cutoff=2)\n",
      "    \n",
      "    relevance = 0\n",
      "    count = 0\n",
      "    for path in paths:\n",
      "        #print path, \n",
      "        l = len(path)\n",
      "        count += 1\n",
      "        weights = []\n",
      "        for i in xrange(l-1):\n",
      "            edge_data = g.get_edge_data(path[i], path[i+1])\n",
      "            if type(edge_data) is dict:\n",
      "                weights.append(edge_data[\"weight\"])\n",
      "        \n",
      "        w = reduce(lambda x, y: x*y, weights)\n",
      "        relevance += w/(l*l)\n",
      "        #print weights, w/len(path)\n",
      "    relevance /= count\n",
      "    print \"Total relevance\", relevance, \"\\n\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}
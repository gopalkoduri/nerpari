{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Run this file from the place where wiki dump is extracted\n",
      "\n",
      "data_dir = \"/homedtic/gkoduri/data/wiki/extracted\"\n",
      "code_dir = \"/homedtic/gkoduri/workspace/ontology-learning\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from glob import glob\n",
      "import sys\n",
      "import codecs\n",
      "import pickle\n",
      "from uuid import uuid5, NAMESPACE_URL\n",
      "from os.path import basename\n",
      "from BeautifulSoup import BeautifulSoup"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def build_index(arg):\n",
      "    index = {}\n",
      "    \n",
      "    files = glob(data_dir + \"/\" + arg + \"/wiki*\")\n",
      "    identifier = str(uuid5(NAMESPACE_URL, arg))\n",
      "    \n",
      "    log_file = code_dir + \"/data/\" + identifier + \"_log.txt\"\n",
      "    log = codecs.open(log_file, \"w\")\n",
      "    \n",
      "    for f in files:\n",
      "        print f\n",
      "        data = codecs.open(f, 'r', 'utf-8').readlines()\n",
      "        size = len(data)\n",
      "        step = 100\n",
      "        for ind in xrange(0, size, step):\n",
      "            try:\n",
      "                soup = BeautifulSoup(\"\".join(data[ind:ind+step]))\n",
      "            except UnicodeEncodeError, UnicodeDecodeError:\n",
      "                log.write(f + \"\\t\" + str(ind) + \"\\n\")\n",
      "            pages = soup.findAll('doc')\n",
      "            for page in pages:\n",
      "                page_title = page.attrs[2][1]\n",
      "                index[page_title] = arg + \"/\" + basename(f)\n",
      "    \n",
      "    log.close()\n",
      "    \n",
      "    index_file = code_dir + \"/data/\" + identifier + \".pickle\"\n",
      "    pickle.dump(index, file(index_file, \"w\"))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def merge_indexes(files):\n",
      "    whole_index = {}\n",
      "    for f in files:\n",
      "        print f\n",
      "        data = pickle.load(file(f))\n",
      "        whole_index.update(data)\n",
      "    \n",
      "    whole_index_lower = {}\n",
      "    for k, v in whole_index.items():\n",
      "        whole_index_lower[k.lower()] = v\n",
      "        \n",
      "    return whole_index_lower"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "if __name__ == \"__main__\":\n",
      "    #build_index(sys.argv[1])\n",
      "    \n",
      "    files = glob(code_dir + \"/data/wiki_index/*.pickle\")\n",
      "    whole_index = merge_indexes(files)\n",
      "    \n",
      "    pickle.dump(whole_index, file(code_dir + \"/data/wiki_index.pickle\", \"w\"))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}
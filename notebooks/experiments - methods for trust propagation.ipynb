{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from __future__ import division\n",
      "\n",
      "import graph_tool.all as gt\n",
      "import networkx as nx\n",
      "import community as c\n",
      "import pickle\n",
      "from pylab import *\n",
      "\n",
      "%matplotlib tk\n",
      "rcParams['figure.figsize'] = 16, 12"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "annotations = pickle.load(file('/homedtic/gkoduri/workspace/relation-extraction/data/annotations.pickle'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fname = '/homedtic/gkoduri/workspace/relation-extraction/data/carnatic_music_hyperlinks.graphml'\n",
      "nx_g = nx.read_graphml(fname, node_type=unicode)\n",
      "print nx_g.number_of_nodes(), nx_g.number_of_edges()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Simple trust propagation in hyperlink graph\n",
      "The method is as follows:\n",
      "\n",
      "* Start with a labelled set of nodes selected by inverse page rank.\n",
      "* Assign a trust of 1 to carnatic nodes, -1 to non-carnatic nodes.\n",
      "* Set a threshold on how far you would like to propagate this trust from each node (**parameter: distance**)\n",
      "* Propagate by\n",
      "    * Dampening (should be good with sparse network)\n",
      "    * Splitting (should be good with dense network)\n",
      "    * An interplay of both\n",
      "* Classify the nodes by summing up all the propagations each node received."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Select a set of nodes based on inverse pagerank"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rev_g = nx_g.reverse(copy=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "inv_pageranks = nx.pagerank(rev_g)\n",
      "inv_pageranks = inv_pageranks.items()\n",
      "inv_pageranks = sorted(inv_pageranks, key=lambda x:x[1], reverse=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "selected_nodes = [i[0] for i in inv_pageranks[:70]]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pos = [i for i in selected_nodes if annotations[i] == \"carnatic\"]\n",
      "neg = [i for i in selected_nodes if annotations[i] != \"carnatic\"]\n",
      "\n",
      "print len(pos), len(neg)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Select a set of nodes based on eigenvector centrality"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "centralities = nx.eigenvector_centrality(nx_g)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "####A detour to check how good eigenvector centralities are to classify"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "neg = [i for i in annotations if annotations[i] != \"carnatic\"]\n",
      "pos = [i for i in annotations if annotations[i] == \"carnatic\"]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from __future__ import division\n",
      "\n",
      "eig_limits = np.arange(0.00001, 0.01, 0.00003)\n",
      "neg_n = []\n",
      "neg_p = []\n",
      "pos_n = []\n",
      "pos_p = []\n",
      "\n",
      "for eig_limit in eig_limits:\n",
      "    nbunch = [n for n,v in centralities if v < eig_limit]\n",
      "    neg_n.append(len(set(neg).intersection(nbunch))/len(neg))\n",
      "    neg_p.append(len(set(neg).intersection(nbunch))/len(nbunch))\n",
      "    pos_n.append(len(set(pos).intersection(nbunch))/len(pos))\n",
      "    pos_p.append(len(set(pos).intersection(nbunch))/len(nbunch))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plot(eig_limits, neg_p, label=\"neg_p\")\n",
      "plot(eig_limits, neg_n, label=\"neg_n\")\n",
      "plot(eig_limits, pos_p, label=\"pos_p\")\n",
      "plot(eig_limits, pos_n, label=\"pos_n\")\n",
      "legend()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "centralities = centralities.items()\n",
      "centralities = sorted(centralities, key=lambda x:x[1], reverse=True)\n",
      "selected_nodes = [i[0] for i in centralities[:60]]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pos = [i for i in selected_nodes if annotations[i] == \"carnatic\"]\n",
      "neg = [i for i in selected_nodes if annotations[i] != \"carnatic\"]\n",
      "\n",
      "print len(pos), len(neg)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def propagate_trust(g, src_bunch, method=\"basic\", damp_factor=0.85, split_with=\"num_edges\", clean_g=nx_g):\n",
      "    \"\"\"\n",
      "    Propagates trust from a given set of nodes to their neighbors.\n",
      "    The function expects the properties 'trust' defined on all src_bunch.\n",
      "    It returns the modified graph and those set of nodes which are assigned\n",
      "    trust during this execution/iteration.\n",
      "    \n",
      "    Methods available:\n",
      "    \n",
      "    basic: It propagates the trust value of the src node to it's neighbor \n",
      "    without modification. An average of the total sum received at the \n",
      "    destination node becomes its trust score.\n",
      "    \n",
      "    dampening: It propagates the trust value of the src node to it's neighbor\n",
      "    by dampening the trust by a given damp_factor. An average of the total sum \n",
      "    received at the destination node becomes its trust score.\n",
      "    \n",
      "    splitting: It propagates the trust value of the src node to it's neighbor\n",
      "    by splitting the trust among the neighbors. The split can be based on the absolute\n",
      "    number of out edges, or their weights (split_with argument can num_edges/weights).\n",
      "    An average of the total sum received at the destination node becomes its trust score.\n",
      "    \n",
      "    \"\"\"\n",
      "    fresh_bunch = set()\n",
      "    \n",
      "    for src in src_bunch:\n",
      "        if \"trust\" not in g[src].keys():\n",
      "            print src, \"has no trust assigned.\"\n",
      "            continue\n",
      "            \n",
      "        neighbors = [i[1] for i in clean_g.out_edges(src)]\n",
      "        if len(neighbors) == 0:\n",
      "            print src, \"does not have out going edges.\"\n",
      "            continue\n",
      "        \n",
      "        fresh_bunch = fresh_bunch.union(neighbors)\n",
      "        #To avoid recomputing over and again...\n",
      "        if method == \"splitting\" and split_with == \"num_edges\":\n",
      "            trust_share = g[src][\"trust\"]/len(neighbors)\n",
      "        \n",
      "        for dest in neighbors:\n",
      "            if method == \"basic\":\n",
      "                if \"trust\" in g[dest].keys():\n",
      "                    g[dest][\"trust\"] += g[src][\"trust\"]\n",
      "                    g[dest][\"trust\"] /= 2.0\n",
      "                else:\n",
      "                    g[dest][\"trust\"] = g[src][\"trust\"]\n",
      "                        \n",
      "            elif method == \"dampening\":\n",
      "                if \"trust\" in g[dest].keys():\n",
      "                    g[dest][\"trust\"] += g[src][\"trust\"]*damp_factor\n",
      "                    g[dest][\"trust\"] /= 2.0\n",
      "                else:\n",
      "                    g[dest][\"trust\"] = g[src][\"trust\"]*damp_factor\n",
      "                \n",
      "            elif method == \"splitting\":\n",
      "                if method == \"splitting\" and split_with == \"weights\":\n",
      "                    trust_share = g[src][\"trust\"]*g[src][dest][\"weight\"]\n",
      "                    \n",
      "                if \"trust\" in g[dest].keys():\n",
      "                    g[dest][\"trust\"] += trust_share\n",
      "                    g[dest][\"trust\"] /= 2.0\n",
      "                else:\n",
      "                    g[dest][\"trust\"] = trust_share\n",
      "                \n",
      "            elif method == \"hybrid\":\n",
      "                pass\n",
      "            else:\n",
      "                print \"Method not implemented\"\n",
      "                return\n",
      "    \n",
      "    return g, fresh_bunch"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "g = nx_g.copy()\n",
      "\n",
      "for src in selected_nodes:\n",
      "    if annotations[src] == \"carnatic\":\n",
      "        g[src][\"trust\"] = 1\n",
      "    else:\n",
      "        g[src][\"trust\"] = -1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "num_iter = 3\n",
      "fresh_bunch = selected_nodes\n",
      "for i in xrange(num_iter):\n",
      "    print i, len(fresh_bunch)\n",
      "    g, fresh_bunch = propagate_trust(g, fresh_bunch, method=\"dampening\", damp_factor=0.85)\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "trusts = [g[node][\"trust\"] for node in nodes if \"trust\" in g[node].keys()]\n",
      "res = hist(trusts, bins=1000)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "good_nodes = []\n",
      "bad_nodes = []\n",
      "orphans = []\n",
      "for n in g.nodes():\n",
      "    if \"trust\" in g[n].keys():\n",
      "        if g[n][\"trust\"] > 0:\n",
      "            good_nodes.append(n)\n",
      "        else:\n",
      "            bad_nodes.append(n)\n",
      "    else:\n",
      "        orphans.append(n)\n",
      "print len(selected_nodes), len(good_nodes), len(bad_nodes), len(orphans)\n",
      "good_nodes"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tp = 0\n",
      "tn = 0\n",
      "fp = 0\n",
      "fn = 0\n",
      "\n",
      "for n in good_nodes:\n",
      "    if n in annotations.keys():\n",
      "        if annotations[n] == \"carnatic\":\n",
      "            tp += 1\n",
      "        else:\n",
      "            fp += 1\n",
      "\n",
      "for n in bad_nodes + orphans:\n",
      "    if n in annotations.keys():\n",
      "        if annotations[n] != \"carnatic\":\n",
      "            tn += 1\n",
      "        else:\n",
      "            fn += 1\n",
      "\n",
      "precision = tp/(tp+fp)\n",
      "recall = tp/(tp+fn)\n",
      "f_measure = 2*tp/(2*tp+fp+fn)\n",
      "print precision, recall, f_measure\n",
      "print tn/(tn+fn)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Community analysis with a seed set\n",
      "\n",
      "**_Remarks: Works well!_**\n",
      "\n",
      "**Method:**\n",
      "\n",
      "* Build a hyperlink graph\n",
      "* Label a seed set of nodes whether they are carnatic or non-carnatic\n",
      "* Perform community-analysis on the undirected version of the graph and keep the big ones\n",
      "* Note the ochiai-coefficients of each community with the carnatic and non-carnatic labeled sets\n",
      "* Classify the communities into carnatic and non-carnatic sets"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fname = '/homedtic/gkoduri/workspace/relation-extraction/data/carnatic_hyperlinks.graphml'\n",
      "nx_g = nx.read_graphml(fname, node_type=unicode)\n",
      "print nx_g.number_of_nodes(), nx_g.number_of_edges()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "g = nx_g.to_undirected()\n",
      "dendogram = c.generate_dendogram(g)\n",
      "#partition = c.best_partition(g)\n",
      "partition = c.partition_at_level(dendogram, 0)\n",
      "print len(np.unique(partition.values()))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "categories = {}\n",
      "min_com_size = 10\n",
      "\n",
      "for com in set(partition.values()) :\n",
      "    list_nodes = [nodes for nodes in partition.keys()\n",
      "                                if partition[nodes] == com]\n",
      "\n",
      "    if len(list_nodes) > min_com_size:\n",
      "        categories[com] = list_nodes\n",
      "        print com, len(list_nodes)\n",
      "        print"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for com, nbunch in categories.items():\n",
      "    print com, len(nbunch), nbunch[:100]\n",
      "    print"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "good_nodes = [i for i in selected_nodes if annotations[i] == \"carnatic\"]\n",
      "bad_nodes = [i for i in selected_nodes if annotations[i] != \"carnatic\"]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for com, nbunch in categories.items():\n",
      "    print com, len(nbunch), ochiai_coefficient(good_nodes, nbunch), ochiai_coefficient(bad_nodes, nbunch)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fgood_nodes = categories[1] + categories[2]\n",
      "fbad_nodes = categories[0] + categories[3] + categories[4]\n",
      "\n",
      "tp = 0\n",
      "tn = 0\n",
      "fp = 0\n",
      "fn = 0\n",
      "\n",
      "for n in fgood_nodes:\n",
      "    if n in annotations.keys():\n",
      "        if annotations[n] == \"carnatic\":\n",
      "            tp += 1\n",
      "        else:\n",
      "            fp += 1\n",
      "\n",
      "for n in fbad_nodes:\n",
      "    if n in annotations.keys():\n",
      "        if annotations[n] != \"carnatic\":\n",
      "            tn += 1\n",
      "        else:\n",
      "            fn += 1\n",
      "\n",
      "precision = tp/(tp+fp)\n",
      "recall = tp/(tp+fn)\n",
      "f_measure = 2*tp/(2*tp+fp+fn)\n",
      "print precision, recall, f_measure\n",
      "print tn/(tn+fn)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clean_g = nx_g.subgraph(fgood_nodes)\n",
      "nx.write_graphml(clean_g, '/homedtic/gkoduri/workspace/relation-extraction/data/carnatic_hyperlinks_clean.graphml')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import cStringIO\n",
      "\n",
      "def propmap_len(vertices, propmap):\n",
      "    count = 0\n",
      "    for v in vertices:\n",
      "        if propmap[v]:\n",
      "            count += 1\n",
      "    return count\n",
      "\n",
      "def convert_graph(src_g, to=\"graphtool\"):\n",
      "    buf = cStringIO.StringIO()\n",
      "    if to == \"graphtool\":\n",
      "        nx.write_graphml(src_g, buf, encoding='utf-8')\n",
      "        buf.flush()\n",
      "        buf.reset()\n",
      "        dest_g = gt.Graph()\n",
      "        dest_g.load(buf, fmt=\"xml\")\n",
      "    else:\n",
      "        src_g.save(buf, fmt=\"xml\")\n",
      "        buf.flush()\n",
      "        buf.reset()\n",
      "        dest_g = nx.read_graphml(buf, node_type=unicode)\n",
      "    return dest_g\n",
      "\n",
      "def sample_graph(g, num_nodes=100):\n",
      "    nodes = array(g.nodes())\n",
      "    indices = unique(random_integers(0, len(nodes), num_nodes+100))[:num_nodes]\n",
      "    nodes = nodes[indices]\n",
      "    sub_graph = g.subgraph(nodes)\n",
      "    return sub_graph\n",
      "\n",
      "def filter_edgeweight(g, thresh, weight_type=\"distance\"):\n",
      "    filt_g = g.copy()\n",
      "    for u,v,d in filt_g.edges(data=True):\n",
      "        if weight_type == \"distance\":\n",
      "            if d[\"weight\"] > thresh:\n",
      "                filt_g.remove_edge(u,v)\n",
      "        elif weight_type == \"similarity\":\n",
      "            if d[\"weight\"] < thresh:\n",
      "                filt_g.remove_edge(u,v)\n",
      "                \n",
      "    nodes = filt_g.nodes()\n",
      "    for n in nodes:\n",
      "        if filt_g.degree(n) == 0:\n",
      "            filt_g.remove_node(n)\n",
      "        \n",
      "    return filt_g\n",
      "\n",
      "def invert_weights(g):\n",
      "    for u,v,d in g.edges(data=True):\n",
      "        d[\"weight\"] = 1.0-d[\"weight\"]+0.000001\n",
      "    return g\n",
      "\n",
      "def ochiai_coefficient(x, y):\n",
      "    x = set(x)\n",
      "    y = set(y)\n",
      "    return len(x.intersection(y))/(sqrt(len(x)*len(y)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}